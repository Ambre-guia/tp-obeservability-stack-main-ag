# ============================================================================
# LOGSTASH PIPELINE CONFIGURATION
# Collecte, transforme et envoie les logs vers Elasticsearch
# ============================================================================

input {
  # Entrée TCP pour recevoir les logs des services
  tcp {
    port => 5000
    codec => json_lines
    tags => ["tcp"]
  }
  
  # Entrée stdin pour tests manuels
  stdin {
    codec => json
    tags => ["stdin"]
  }
  
  # Logs Docker via le driver syslog (optionnel)
  syslog {
    port => 5514
    tags => ["syslog", "docker"]
  }
}

filter {
  # Analyser les logs JSON structurés
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      target => "parsed"
    }
    
    # Copier les champs parsés au niveau racine
    if [parsed] {
      mutate {
        rename => {
          "[parsed][timestamp]" => "[@timestamp]"
          "[parsed][level]" => "log_level"
          "[parsed][service]" => "service_name"
          "[parsed][message]" => "log_message"
          "[parsed][trace_id]" => "trace_id"
          "[parsed][span_id]" => "span_id"
        }
      }
    }
  }
  
  # Parser les logs non-structurés avec grok
  else {
    grok {
      match => {
        "message" => [
          "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} %{GREEDYDATA:log_message}",
          "%{SYSLOGTIMESTAMP:timestamp} %{LOGLEVEL:log_level} %{GREEDYDATA:log_message}",
          "%{GREEDYDATA:log_message}"
        ]
      }
    }
    
    # Convertir le timestamp en format Elasticsearch
    if [timestamp] {
      date {
        match => ["timestamp", "ISO8601", "MMM dd HH:mm:ss", "yyyy-MM-dd HH:mm:ss"]
        target => "@timestamp"
      }
    }
  }
  
  # Ajouter des tags selon le service
  if [service_name] == "frontend" {
    mutate {
      add_tag => ["nodejs", "frontend-service"]
    }
  } else if [service_name] == "backend" {
    mutate {
      add_tag => ["python", "backend-service"]
    }
  }
  
  # Normaliser le niveau de log
  if [log_level] {
    mutate {
      uppercase => ["log_level"]
    }
  }
  
  # Ajouter des métadonnées
  mutate {
    add_field => {
      "[@metadata][index_prefix]" => "logs"
      "environment" => "production"
    }
  }
  
  # Supprimer les champs temporaires
  mutate {
    remove_field => ["parsed", "message"]
  }
}

output {
  # Envoyer vers Elasticsearch
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOSTS:elasticsearch:9200}"]
    index => "logs-%{+YYYY.MM.dd}"
    
    # Configuration de l'index
    template_name => "logs"
    template_overwrite => true
    
    # Gestion des erreurs
    manage_template => true
  }
  
  # Sortie stdout pour debug (à désactiver en production)
  stdout {
    codec => rubydebug {
      metadata => true
    }
  }
}
